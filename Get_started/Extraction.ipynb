{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36ccd3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c2ac1",
   "metadata": {},
   "source": [
    "### The Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45288946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel): \n",
    "   \"\"\"Information about a person.\"\"\"\n",
    "   \n",
    "   name: Optional[str] = Field(default=None, description=\"The name of the person.\")\n",
    "   hair_color: Optional[str] = Field(default=None, description=\"The solor of the person's hair if known.\")\n",
    "   height_in_meters: Optional[str] = Field(default=None, description=\"Height measured in meters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7b5db",
   "metadata": {},
   "source": [
    "### The Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb33f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\", \n",
    "         \"You are an expert extraction algorithm. \"\n",
    "         \"Only extract relevant information from the text. \"\n",
    "         \"If you do not know value of an attribute asked to extract, \"\n",
    "         \"return null for the attribute's value\"\n",
    "      ),\n",
    "      (\"human\", \"{text}\"),\n",
    "   ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58f7f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "structured_llm = init_chat_model(model=\"gpt-4o-mini\", temperature=0).with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e6f41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Alan Smith is 6 feet tall and has blonde hair.\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "\n",
    "response = structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7efe490c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alan Smith', hair_color='blonde', height_in_meters='1.83')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7540aa",
   "metadata": {},
   "source": [
    "### Multiple Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05cc4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel): \n",
    "   \"\"\"Information about a person.\"\"\"\n",
    "   \n",
    "   name: Optional[str] = Field(default=None, description=\"The name of the person.\")\n",
    "   hair_color: Optional[str] = Field(default=None, description=\"The color of the person's hair if known.\")\n",
    "   height_in_meters: Optional[str] = Field(default=None, description=\"Height measured in meters.\")\n",
    "   \n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extract data about people.\"\"\"\n",
    "    \n",
    "    People: list[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6ed2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = init_chat_model(model=\"gpt-4o-mini\", temperature=0).with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b383a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"M name is Jeff, my hair is black and  I am 6 feet tall. Anna has the same color hair as me.\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "response = structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d546873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(People=[Person(name='Jeff', hair_color='black', height_in_meters='1.83'), Person(name='Anna', hair_color='black', height_in_meters=None)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82270ca",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ff1dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\",\n",
    "         \"You are an expert extraction algorithm. \"\n",
    "         \"Only extract relevant information from the text. \"\n",
    "         \"If you do not know value of an attribute asked to extract, \"\n",
    "         \"to extract, return null for the attribute's value\"\n",
    "      ),\n",
    "      #!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "      MessagesPlaceholder(\"examples\"),\n",
    "      #!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "      (\"human\", \"{text}\")\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b704478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content=\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know value of an attribute asked to extract, to extract, return null for the attribute's value\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Extract info from: Steve Jobs founded Apple.', additional_kwargs={}, response_metadata={}), AIMessage(content='{\"name\": \"Steve Jobs\", \"company\": \"Apple\"}', additional_kwargs={}, response_metadata={}), HumanMessage(content='Bill Gates founded Microsoft.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Example few-shot messages\n",
    "examples = [\n",
    "    HumanMessage(content=\"Extract info from: Steve Jobs founded Apple.\"),\n",
    "    AIMessage(content='{\"name\": \"Steve Jobs\", \"company\": \"Apple\"}')\n",
    "]\n",
    "\n",
    "# Final input\n",
    "text_input = \"Bill Gates founded Microsoft.\"\n",
    "\n",
    "# Invoke with both examples + main text\n",
    "prompt = prompt_template.invoke({\n",
    "    \"examples\": examples,\n",
    "    \"text\": text_input\n",
    "})\n",
    "\n",
    "print(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
